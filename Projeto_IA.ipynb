{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40b90843"
   },
   "source": [
    "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Template para o Colab do Projeto Semestral**\n",
    "---\n",
    "\n",
    "Atenção, podem ser que nem todas as tarefas sejam executadas no Colab (a aplicação por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR6kcPlTeV_n"
   },
   "source": [
    "Além disso a entrega deve incluir:\n",
    "\n",
    "1. **Um GitHub público do projeto**\n",
    "2. **Código completo e executável em um notebook Python (este template)**\n",
    "3. **Uma aplicação streamlit para consumo do modelo**\n",
    "4. **Um texto/artigo do projeto**\n",
    "5. **Um vídeo (link YouTube ou outro) de no máximo 3min de apresentação do projeto**\n",
    "\n",
    "Um **`readme.md`** no GitHub público do projeto deve indicar (um índice) cada uma dessas entregas.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYx9D4GZA5o9"
   },
   "outputs": [],
   "source": [
    "#@title **Identificação do Grupo**\n",
    "\n",
    "#@markdown Integrantes do Grupo, nome completo em orgem alfabética\n",
    "Aluno1 = '10403109, Erik Samuel Viana Hsu' #@param {type:\"string\"}\n",
    "Aluno2 = '10400995, Mateus Kenzo Iochimoto' #@param {type:\"string\"}\n",
    "Aluno3 = '10400764, Thiago Shihan Cardoso Toma' #@param {type:\"string\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-MbC50IHTmh3"
   },
   "outputs": [],
   "source": [
    "#@title Assinale aqui a sua opção de Projeto\n",
    "Projeto = \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\" #@param [\"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\", \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxYbSf6mVM7y"
   },
   "source": [
    "# **Resumo**\n",
    "\n",
    "# **1. Objetivo do projeto**\n",
    "\n",
    "O objetivo deste projeto é construir um sistema de **tradução automática neural** do inglês para o português, utilizando modelos pré-treinados da biblioteca **Hugging Face Transformers**. A proposta é aplicar técnicas modernas de NLP para adaptar um modelo de tradução com dados personalizados, visando melhorar sua performance em um domínio específico.\n",
    "\n",
    "# **2. Fontes dos dados e dados originais (coletados)**\n",
    "Os dados utilizados neste projeto foram extraídos do **EMEA Parallel Corpus** (European Medicines Agency), um conjunto de frases paralelas em inglês e português, focado no domínio biomédico. Os arquivos utilizados foram:\n",
    "\n",
    "- `EMEA.en-pt.en` — Frases em inglês  \n",
    "- `EMEA.en-pt.pt` — Traduções correspondentes em português\n",
    "\n",
    "# 3. **Ferramentas/pacotes de IA a serem utilizados para a construção da solução**\n",
    "\n",
    "- **Transformers** — Para carregamento e fine-tuning do modelo `Helsinki-NLP/opus-mt-en-ROMANCE`\n",
    "- **Datasets** — Para manipulação e tokenização dos dados\n",
    "- **Evaluate** — Para cálculo da métrica `sacreBLEU`\n",
    "- **PyTorch** — Backend para o treinamento\n",
    "\n",
    "# 4. **Uma prévia dos resultados.**\n",
    "O modelo foi ajustado com 2000 pares de frases para treino e 500 para avaliação.\n",
    "\n",
    "Para testar a função de tradução, passamos uma frase em inglês como parâmetro de entrada e a saída é a frase traduzida em português. Por exemplo, se a frase for \"Keep medicine away from children\", a tradução será \"Manter os medicamentos longe das crianças\". Outras frases e entradas podem ser testadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctroSu6jNABS"
   },
   "source": [
    "# **Apresentação dos dados**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL-g-h18YrhR"
   },
   "source": [
    "Utilizaremos o corpus EMEA (European Medicines Agency), que contém traduções de bulas de medicamentos em vários idiomas. Os dados estão disponíveis publicamente via [OPUS](https://opus.nlpl.eu/EMEA.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvjqE7zw5fBU",
    "outputId": "015945ff-4d21-4ab8-84ce-3ae50234608c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-31 13:48:05--  https://object.pouta.csc.fi/OPUS-EMEA/v3/moses/en-pt.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35242984 (34M) [application/zip]\n",
      "Saving to: ‘emea_en-pt.zip’\n",
      "\n",
      "emea_en-pt.zip      100%[===================>]  33.61M  11.1MB/s    in 3.0s    \n",
      "\n",
      "2025-05-31 13:48:09 (11.1 MB/s) - ‘emea_en-pt.zip’ saved [35242984/35242984]\n",
      "\n",
      "Archive:  emea_en-pt.zip\n",
      "  inflating: EMEA.en-pt.en           \n",
      "  inflating: EMEA.en-pt.pt           \n",
      "  inflating: README                  \n"
     ]
    }
   ],
   "source": [
    "!wget https://object.pouta.csc.fi/OPUS-EMEA/v3/moses/en-pt.txt.zip -O emea_en-pt.zip\n",
    "!unzip emea_en-pt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iy_B3tehZBXK",
    "outputId": "6fe39586-928f-4037-d064-d697aa2bc0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: European Medicines Agency\n",
      "PT: European Medicines Agency\n",
      "---\n",
      "EN: EMEA/ H/ C/ 471\n",
      "PT: EMEA/ H/ C/ 471\n",
      "---\n",
      "EN: EUROPEAN PUBLIC ASSESSMENT REPORT (EPAR)\n",
      "PT: RELATÓRIO PÚBLICO EUROPEU DE AVALIAÇÃO (EPAR)\n",
      "---\n",
      "EN: ABILIFY\n",
      "PT: ABILIFY\n",
      "---\n",
      "EN: EPAR summary for the public\n",
      "PT: Resumo do EPAR destinado ao público\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualização de algumas amostras\n",
    "with open(\"EMEA.en-pt.en\", encoding=\"utf-8\") as f_en, open(\"EMEA.en-pt.pt\", encoding=\"utf-8\") as f_pt:\n",
    "    for _ in range(5):\n",
    "        print(\"EN:\", f_en.readline().strip())\n",
    "        print(\"PT:\", f_pt.readline().strip())\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDzwn_5AMZ52"
   },
   "source": [
    "# **Preparação e transformação dos dados**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5si6yrzMZLxG",
    "outputId": "018ab7b6-8062-4f58-9b3d-0f746b842952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.2\n",
      "    Uninstalling transformers-4.52.2:\n",
      "      Successfully uninstalled transformers-4.52.2\n",
      "Successfully installed transformers-4.52.4\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: portalocker, colorama, sacrebleu, evaluate\n",
      "Successfully installed colorama-0.4.6 evaluate-0.4.3 portalocker-3.1.1 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hAtTmqbhkny",
    "outputId": "1760eb8e-7055-4b41-a91d-de1fdebfa3f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 973929\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 108215\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Função que carrega os dados personalizados de tradução a partir de 2 arquivos de texto\n",
    "def load_custom_data():\n",
    "    with open(\"EMEA.en-pt.en\", encoding=\"utf-8\") as f_en, open(\"EMEA.en-pt.pt\", encoding=\"utf-8\") as f_pt:\n",
    "        data = [{\"translation\": {\"en\": en.strip(), \"pt\": pt.strip()}} for en, pt in zip(f_en, f_pt)] # cria uma lista de dicionários, onde cada item é um par de tradução\n",
    "    return Dataset.from_list(data) # converte a lista de pares de tradução em um objeto Dataset do Hugging Face\n",
    "\n",
    "dataset = load_custom_data() # carrega o dataset personalizado com a função acima\n",
    "dataset = dataset.train_test_split(test_size=0.1) # divide o dataset em dois subconjuntos -> teste (10%) e treino (90%)\n",
    "dataset # exibe o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnJHmydNNfl0"
   },
   "source": [
    "# **Fine Tuning do modelo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJU-gnj1h7l5"
   },
   "source": [
    "Nessa etapa, utilizamos o modelo `Helsinki-NLP/opus-mt-en-ROMANCE` (o -pt era público mas ficou privado, mas o ROMANCE contempla pt também) com ajustes finos baseados no nosso conjunto técnico (bula de remédios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531,
     "referenced_widgets": [
      "4952d8b9cdc1476b9bfddeb5596b50f3",
      "ba95f9d9de63432e971045d75ef41ed9",
      "1d199c1fd41c4f0e8a3eee0a1ad89f38",
      "22804010bb94455b894053159252728c",
      "1984e14dde6f479090489ddb50f58636",
      "52e27a649cb948eba995881f6eaf8185",
      "b4b4a455568e496e84af7b07cf76068a",
      "eeb2d149a9594549a3e81eac5c18435c",
      "60d678f8f4cf444797a0d866f638095e",
      "80b7098e9847476391cc7fb7f81720e6",
      "7ba89265d2aa49a9afbff6a911bab436",
      "4ffe923a632c4645abaa3152b50680e8",
      "8f1233f56d244ea89883488056948308",
      "f50cbb3861d44642964bd2cf8e1a18f4",
      "6a5d8231e2094a99a8c29d646b105954",
      "a756ed8f04754cd4975954c6899ac61c",
      "8f12aa226e1a4646ba978e5aaab0a637",
      "32b79b8f67cf4941917ac75667014816",
      "47cd172bab534af88149e533a5de1d3e",
      "531a37152e5b44bba611e006d898c51a",
      "749bdf6a2d934a2fb829e3fd13458121",
      "0829c933a56845b09ba0ede1e2597cd8",
      "d3f46e02139d44c3a8eada31a16640ba",
      "09443468f40644d197583a27312e7793",
      "81586d632d184755a3ee772f8e9d1823",
      "21b224c6eedd4de1b91924ccc8c63fe5",
      "2bc00121890347c68dba8d39cbadb636",
      "595e5c0534884f4aaeba2e62c591925d",
      "04707da23ca048a183acf7524d80672c",
      "7589937fd6914c53834cf7c3cef35287",
      "cc248ac5672e410d8a42a8c7b20fcd33",
      "5d2175890b544e1a998fb743a9fd586d",
      "b77625f8aca04fe6bbfd526f954297ac",
      "70e22bb471c949379af8dd8390150751",
      "42027bd626ba411c8af83b0e083ce98b",
      "5a59c55a5e0c43d3bc71db645beae37f",
      "71f052a5c8b04d6ebc89e6a3aecf571d",
      "3299ddd0cc3a468a8126df5a0367e2be",
      "52209b0b15cd49a689687a8c7056c404",
      "56badbc17c394fb7bb087cb8f8a90a17",
      "3b90e43782e64d308575109669708ef0",
      "f9a33227d82d48fb91bdd8c354a6d341",
      "4887476605394852a5a12694d2dd11b0",
      "20084ddb1b4a44d49e9a9a171802425d",
      "535fc6ab1ce74f08a589e780649d297e",
      "afb81575fde5407b9bbc61e6d889f95d",
      "2a57ea3de85641d78748af75ea1ddda2",
      "fa153c51b55c4147896b2e395141214c",
      "fb93cc902ddf46f19dadb19e09b7ba95",
      "97013c4c54f94a0c87866f8240edd066",
      "53f04de93f1a4ea2ab4350d381a5cc8d",
      "8fb3811fa0e64bf58bbdb8505f778654",
      "200ad2cf06e14e309e0e937439201701",
      "da774ec7fd5b447388ef3d3988203e90",
      "34e68cab33234c7ba11763bb97030678",
      "4ca822a90f654f4f9242909e15e59103",
      "44368604be6c4bf4b985d5cc4ca43d0c",
      "07005383fc0b46839732e70ead90916b",
      "14f99ff4ea2c4ae3ac144a39621b7433",
      "f9207acc98d74040bb4992e3699f7f7b",
      "d0399464429c49a7ab10224a79daed51",
      "0902e46f8be24446ad7208a6aba73328",
      "d05bd0b2ae374832857b196bbfd44b13",
      "fb0b874523f7458abbc4b45aa64f0f72",
      "a931fde86c214a83b6f216bf58c06c41",
      "928f34aed1f444268b1814c5745483a7",
      "a22c8634b0834b678b2dfffd6009cdb0",
      "da6f548e9ddf427287036114bfa02bf6",
      "f39ae31a514248598cec0501620a084a",
      "7385eda159f24362a1bfa14c898e4fbb",
      "08c636839cfa4d76b34392a8ab3ce412",
      "3893f23c09ab49878625d9bc01adcfd7",
      "cc43d545bb824e5bb272402983f64d31",
      "d6aea12d9c614ccb914162dc59a6902a",
      "bdae4540eff44a32bfaf96af649f6c6a",
      "12da532b05f84892a095a5e5f47aafdf",
      "fd52d0f6b9084168abbe50912552b2af",
      "d6d17ffcac634612ac34977f50c6d4d2",
      "ce7464ceffc4490ea931273b7385c7d1",
      "838738dc3dbf49bc8a5c300c72e995ea",
      "aee1828bd0224f608ddf9eb0e6638435",
      "bc1762ad056746aab288acdfeb3eb1b4",
      "b71a206e750243f19e3045b340237d88",
      "9099f6b2b6114077b32c4f4a5db1146c",
      "2d9d76b93a574cf3812795aceafe1f8a",
      "db6dec3734a14fccbaf7126cb827d89d",
      "d2ff47b2345145fa9d5ad188faced27f",
      "737b47a359fd4392b6ee867989f3bd4c",
      "e7a1eb4ef30b48a6b27f99f598e3197f",
      "79d511582f9048afa7c1edeedbbd3620",
      "a3cd3e1d7aca4bb0a7f11b462e33523c",
      "5cf50cc8d7bf4fd6be2ddd56f530b158",
      "9d2c26ad84f242a99654b555df042305",
      "e5774c8bdd8a41c4bf35b7ed7aae6724",
      "f5e178e9de54473aba8f7e9210e50a36",
      "5fdb8ba7a7484a379a404bbd78e63d16",
      "41f3c1aefb594a32b2b40849a1095107",
      "d2604211cdf743839ac765c59578bde4",
      "00213b21a85a4f718f0df95987987c11",
      "504e5e1c0e7c4eb4b03d62fb25915226",
      "bf45d824c75c4ba188b355c9d41c7d47",
      "eb08fd9e593940e0b90437fd4a949b9b",
      "d518239b6fbd40a9ac3c2b28740609e9",
      "e823705bbce44b1f8cf48ee26472d05d",
      "6ab440ce1b6f411bbf2b43bf6d93da51",
      "4fdbb0784e384e4e9b21fa3b59e07840",
      "91bce58fc0e147ddb00c1ce0122dfffc",
      "5002087614df47f6bf84262619aa1074",
      "c9e0579825f949338a267343a6a9ba99",
      "141dd9ecbc7948c3b5e4dd0cc3f57030"
     ]
    },
    "id": "XAeRE1v9hsPP",
    "outputId": "73b516eb-f9c6-46ea-b222-755c160cc85f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4952d8b9cdc1476b9bfddeb5596b50f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffe923a632c4645abaa3152b50680e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f46e02139d44c3a8eada31a16640ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/799k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e22bb471c949379af8dd8390150751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535fc6ab1ce74f08a589e780649d297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca822a90f654f4f9242909e15e59103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22c8634b0834b678b2dfffd6009cdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d17ffcac634612ac34977f50c6d4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a1eb4ef30b48a6b27f99f598e3197f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/973929 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504e5e1c0e7c4eb4b03d62fb25915226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "# Define o nome do modelo base para tradução do inglês para as línguas românicas (inclui pt, es, fr, etc)\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\"\n",
    "\n",
    "#Carrega o tokenizer, transformando os textos em tokens\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Carrega o modelo pré treinado de tradução com base no nome fornecido\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "#Função que pré-processa os dados de entrada para o treinamento\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]] # extrai os textos em inglês da estrutura translation do dataset\n",
    "    targets = [ex[\"pt\"] for ex in examples[\"translation\"]] # extrai as traduções para o português\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\") # tokeniza os textos de entrada\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\") #tokeniza os textos-alvo\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] # add os labels tokenizados ao dicionário de entrada\n",
    "    return model_inputs\n",
    "\n",
    "# Aplica a função de pré processamento a todo o dataset, de forma batched\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "FvUj8l1pjVxH",
    "outputId": "8a917a13-d153-4757-e618-3501cea7353b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-62e1620b5e6c>:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merik0608br\u001b[0m (\u001b[33merik0608br-mackenzie\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250531_140822-o1u66gla</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/erik0608br-mackenzie/huggingface/runs/o1u66gla' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/erik0608br-mackenzie/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/erik0608br-mackenzie/huggingface' target=\"_blank\">https://wandb.ai/erik0608br-mackenzie/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/erik0608br-mackenzie/huggingface/runs/o1u66gla' target=\"_blank\">https://wandb.ai/erik0608br-mackenzie/huggingface/runs/o1u66gla</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:33:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.137725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.1988022003173828, metrics={'train_runtime': 5833.4726, 'train_samples_per_second': 0.686, 'train_steps_per_second': 0.086, 'total_flos': 135593459712000.0, 'train_loss': 0.1988022003173828, 'epoch': 2.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo os argumentos / hiperparâmetros de treinamento\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "small_train_dataset = tokenized_dataset[\"train\"].select(range(2000)) # dataset de treino\n",
    "small_eval_dataset = tokenized_dataset[\"test\"].select(range(500)) #dataset de teste\n",
    "\n",
    "# Trainer com modelo de tradução Seq2Seq\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    ")\n",
    "\n",
    "trainer.train() # inicia o treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1Evo4PmNhBY"
   },
   "source": [
    "# **Avaliação do modelo**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nT7lkz3Pj_E1"
   },
   "source": [
    "Para avaliar a qualidade de tradução, usamos a métrica BLEU (sacrebleu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9a49c2d88f5f4687b2a33cf3b620532a",
      "f67635af619a40b282c73626467bd651",
      "7a91e688497e4134b01e40fef4f22170",
      "42e794b20d924e0e8007dfa0877f049d",
      "3b3cb22e94784e98b90638342ec642ee",
      "b6d50be2b6f048b19a0bde2dbbd458bb",
      "f7cb7d10c6fc461ba2e54cb86da5dea8",
      "e7396dd0be9644879763ba789ce47a4e",
      "f709ae63de49402ca7b46372c4eb61f1",
      "207d944a67cb4702a7821c28fc57f543",
      "f86f3b36844b436e918a31598589b418"
     ]
    },
    "id": "XkPz9hpFj-mY",
    "outputId": "e5018bbf-a208-49e4-f860-65724bc6f6bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a49c2d88f5f4687b2a33cf3b620532a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\") # carrega metrica sacreBLEU\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    # Descompacta os pares de (predições, rótulos/labels)\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # Decodifica as predições\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Substitui -100 pelo token de pad no rótulo\n",
    "    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n",
    "\n",
    "    # Decodifica os rótulos reais (targets) para texto legível, ignorando tokens especiais\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # SacreBLEU espera lista de listas no campo `references`\n",
    "    return metric.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViQfwNxkNj0C"
   },
   "source": [
    "# **Consumo do modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y32fMvFkTPW"
   },
   "source": [
    "Função para traduzir frases novas com o modelo fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJO2QLqqlEv9",
    "outputId": "5be144d3-7b4f-4766-c54e-cd2ac61097bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tradução: Manter os medicamentos longe das crianças.\n"
     ]
    }
   ],
   "source": [
    "def translate(text):\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True) #tokeniza o texto de entrada\n",
    "    translated = model.generate(**inputs) # gera tradução usando o modelo carregado\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True) # decodifica a saída gerada para texto legível\n",
    "\n",
    "# Exemplo de uso\n",
    "exemplo = \"Keep medicine away from children.\"\n",
    "print(\"Tradução:\", translate(exemplo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LtXrRFr4hg3"
   },
   "source": [
    "# **Referências**\n",
    "\n",
    "- OPUS EMEA Corpus: https://opus.nlpl.eu/EMEA.php  \n",
    "- MarianMT - Hugging Face: https://huggingface.co/Helsinki-NLP/opus-mt-en-pt  \n",
    "- Hugging Face Transformers: https://huggingface.co/docs/transformers/index  \n",
    "- Streamlit: https://streamlit.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8crUBC3IQ3U_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BluFtfHuCGzm"
   },
   "outputs": [],
   "source": [
    "#@title **Avaliação**\n",
    "GitHub = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Implementacao_Model_Code = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Aplicacao_Streamlit = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Texto_Artigo  = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Video = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Geral = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "2Gqw7hUZHyle",
    "outputId": "cf56d67f-e7bc-42f0-a81d-f1f808967e93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota final do trabalho 7.9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"alunos\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"tia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1115677\",\n          \"1115665\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" DANIEL HENRIQUE\",\n          \" ADRIANA FUJITA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.9,\n        \"max\": 7.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "alunos"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b0360d6d-a298-4195-9914-febf9bafcd63\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tia</th>\n",
       "      <th>nome</th>\n",
       "      <th>nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1115665</td>\n",
       "      <td>ADRIANA FUJITA</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1115677</td>\n",
       "      <td>DANIEL HENRIQUE</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0360d6d-a298-4195-9914-febf9bafcd63')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-120aa0b0-48d8-4778-aca7-bace2443a5e8\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-120aa0b0-48d8-4778-aca7-bace2443a5e8')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-120aa0b0-48d8-4778-aca7-bace2443a5e8 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_c5110ba6-c42d-43ec-931e-d08b9033ac7e\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alunos')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_c5110ba6-c42d-43ec-931e-d08b9033ac7e button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('alunos');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       tia              nome  nota\n",
       "0  1115665    ADRIANA FUJITA   7.9\n",
       "1  1115677   DANIEL HENRIQUE   7.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title **Nota Final**\n",
    "\n",
    "nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video\n",
    "\n",
    "nota = nota / 10\n",
    "\n",
    "print(f'Nota final do trabalho {nota :.1f}')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alunos = pd.DataFrame()\n",
    "\n",
    "lista_tia = []\n",
    "lista_nome = []\n",
    "\n",
    "for i in range(1,6):\n",
    "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
    "\n",
    "alunos['tia'] = lista_tia\n",
    "alunos['nome'] = lista_nome\n",
    "alunos['nota'] = np.round(nota,1)\n",
    "print()\n",
    "display(alunos)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
